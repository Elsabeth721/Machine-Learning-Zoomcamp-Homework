{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af727419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1462, 9)\n",
      "\n",
      "First few rows:\n",
      "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
      "0      paid_ads         NaN                         1        79450.0   \n",
      "1  social_media      retail                         1        46992.0   \n",
      "2        events  healthcare                         5        78796.0   \n",
      "3      paid_ads      retail                         2        83843.0   \n",
      "4      referral   education                         3        85012.0   \n",
      "\n",
      "  employment_status       location  interaction_count  lead_score  converted  \n",
      "0        unemployed  south_america                  4        0.94          1  \n",
      "1          employed  south_america                  1        0.80          0  \n",
      "2        unemployed      australia                  3        0.69          1  \n",
      "3               NaN      australia                  1        0.87          0  \n",
      "4     self_employed         europe                  3        0.62          1  \n",
      "\n",
      "Column info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1462 entries, 0 to 1461\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   lead_source               1334 non-null   object \n",
      " 1   industry                  1328 non-null   object \n",
      " 2   number_of_courses_viewed  1462 non-null   int64  \n",
      " 3   annual_income             1281 non-null   float64\n",
      " 4   employment_status         1362 non-null   object \n",
      " 5   location                  1399 non-null   object \n",
      " 6   interaction_count         1462 non-null   int64  \n",
      " 7   lead_score                1462 non-null   float64\n",
      " 8   converted                 1462 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 102.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumn info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "713e6de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124e9583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['lead_source', 'industry', 'employment_status', 'location']\n",
      "Numerical columns: ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score', 'converted']\n",
      "Filling missing values in categorical column 'lead_source' with 'NA'\n",
      "Filling missing values in categorical column 'industry' with 'NA'\n",
      "Filling missing values in categorical column 'employment_status' with 'NA'\n",
      "Filling missing values in categorical column 'location' with 'NA'\n",
      "Filling missing values in numerical column 'annual_income' with 0.0\n",
      "\n",
      "Missing values after handling:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(\"Categorical columns:\", list(categorical_cols))\n",
    "print(\"Numerical columns:\", list(numerical_cols))\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        print(f\"Filling missing values in categorical column '{col}' with 'NA'\")\n",
    "        df[col] = df[col].fillna('NA')\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        print(f\"Filling missing values in numerical column '{col}' with 0.0\")\n",
    "        df[col] = df[col].fillna(0.0)\n",
    "\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45000e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for 'industry' column:\n",
      "industry\n",
      "retail           203\n",
      "finance          200\n",
      "other            198\n",
      "healthcare       187\n",
      "education        187\n",
      "technology       179\n",
      "manufacturing    174\n",
      "NA               134\n",
      "Name: count, dtype: int64\n",
      "\n",
      "The most frequent observation (mode) for the column 'industry' is: retail\n"
     ]
    }
   ],
   "source": [
    "industry_mode = df['industry'].mode()[0]\n",
    "industry_counts = df['industry'].value_counts()\n",
    "\n",
    "print(\"Value counts for 'industry' column:\")\n",
    "print(industry_counts)\n",
    "print(f\"\\nThe most frequent observation (mode) for the column 'industry' is: {industry_mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f433fe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features in the dataset:\n",
      "['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score', 'converted']\n",
      "\n",
      "Correlation Matrix:\n",
      "                          number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                  1.000000       0.009770   \n",
      "annual_income                             0.009770       1.000000   \n",
      "interaction_count                        -0.023565       0.027036   \n",
      "lead_score                               -0.004879       0.015610   \n",
      "converted                                 0.435914       0.053131   \n",
      "\n",
      "                          interaction_count  lead_score  converted  \n",
      "number_of_courses_viewed          -0.023565   -0.004879   0.435914  \n",
      "annual_income                      0.027036    0.015610   0.053131  \n",
      "interaction_count                  1.000000    0.009888   0.374573  \n",
      "lead_score                         0.009888    1.000000   0.193673  \n",
      "converted                          0.374573    0.193673   1.000000  \n",
      "\n",
      "The two features with the biggest correlation are: number_of_courses_viewed and converted\n",
      "Correlation coefficient: 0.4359\n",
      "\n",
      "Checking specific pairs mentioned in question:\n",
      "interaction_count and lead_score: 0.0099\n",
      "number_of_courses_viewed and lead_score: -0.0049\n",
      "number_of_courses_viewed and interaction_count: -0.0236\n",
      "annual_income and interaction_count: 0.0270\n"
     ]
    }
   ],
   "source": [
    "# ----------> Question 2\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna('NA')\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].fillna(0.0)\n",
    "\n",
    "print(\"Numerical features in the dataset:\")\n",
    "print(list(numerical_cols))\n",
    "\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "correlation_matrix_no_diag = correlation_matrix.copy()\n",
    "np.fill_diagonal(correlation_matrix_no_diag.values, 0)\n",
    "\n",
    "max_corr = correlation_matrix_no_diag.abs().max().max()\n",
    "max_corr_pair = None\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) == max_corr:\n",
    "            col1 = correlation_matrix.columns[i]\n",
    "            col2 = correlation_matrix.columns[j]\n",
    "            max_corr_pair = (col1, col2, correlation_matrix.iloc[i, j])\n",
    "            break\n",
    "\n",
    "print(f\"\\nThe two features with the biggest correlation are: {max_corr_pair[0]} and {max_corr_pair[1]}\")\n",
    "print(f\"Correlation coefficient: {max_corr_pair[2]:.4f}\")\n",
    "\n",
    "print(\"\\nChecking specific pairs mentioned in question:\")\n",
    "pairs_to_check = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count')\n",
    "]\n",
    "\n",
    "for pair in pairs_to_check:\n",
    "    if pair[0] in numerical_cols and pair[1] in numerical_cols:\n",
    "        corr_value = df[pair[0]].corr(df[pair[1]])\n",
    "        print(f\"{pair[0]} and {pair[1]}: {corr_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6cfd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0f15d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed:\n",
      "Training set: 877 samples (60.0%)\n",
      "Validation set: 292 samples (20.0%)\n",
      "Test set: 293 samples (20.0%)\n",
      "\n",
      "Target column 'converted' in X_train: False\n",
      "Target column 'converted' in X_val: False\n",
      "Target column 'converted' in X_test: False\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('converted', axis=1) \n",
    "y = df['converted'] \n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Data split completed:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTarget column 'converted' in X_train: {'converted' in X_train.columns}\")\n",
    "print(f\"Target column 'converted' in X_val: {'converted' in X_val.columns}\")\n",
    "print(f\"Target column 'converted' in X_test: {'converted' in X_test.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "008543b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution in each split:\n",
      "\n",
      "Full dataset:\n",
      "converted\n",
      "1    0.619015\n",
      "0    0.380985\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training set:\n",
      "converted\n",
      "1    0.619156\n",
      "0    0.380844\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation set:\n",
      "converted\n",
      "1    0.619863\n",
      "0    0.380137\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set:\n",
      "converted\n",
      "1    0.617747\n",
      "0    0.382253\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Target distribution in each split:\")\n",
    "print(\"\\nFull dataset:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTraining set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "print(y_val.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb9b19d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores (rounded to 2 decimals):\n",
      "industry: 0.01\n",
      "location: 0.0\n",
      "lead_source: 0.03\n",
      "employment_status: 0.01\n",
      "\n",
      "The variable with the biggest mutual information score is: lead_source (score: 0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "categorical_vars = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "\n",
    "mi_scores = {}\n",
    "for var in categorical_vars:\n",
    "    mi = mutual_info_score(X_train[var], y_train)\n",
    "    mi_scores[var] = round(mi, 2)\n",
    "\n",
    "print(\"Mutual Information Scores (rounded to 2 decimals):\")\n",
    "for var, score in mi_scores.items():\n",
    "    print(f\"{var}: {score}\")\n",
    "\n",
    "max_mi_var = max(mi_scores, key=mi_scores.get)\n",
    "max_mi_score = mi_scores[max_mi_var]\n",
    "\n",
    "print(f\"\\nThe variable with the biggest mutual information score is: {max_mi_var} (score: {max_mi_score})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "496ebf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['lead_source', 'industry', 'employment_status', 'location']\n",
      "Numerical columns: ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
      "Training set shape after preprocessing: (877, 27)\n",
      "Validation set shape after preprocessing: (292, 27)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print(\"Numerical columns:\", numerical_cols)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Training set shape after preprocessing: {X_train_processed.shape}\")\n",
    "print(f\"Validation set shape after preprocessing: {X_val_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f374d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6849\n",
      "Validation Accuracy (rounded to 2 decimals): 0.68\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_val_pred = model.predict(X_val_processed)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_accuracy_rounded = round(val_accuracy, 2)\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy (rounded to 2 decimals): {val_accuracy_rounded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bac7d366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy with all features: 0.684932\n",
      "Total number of features: 27\n"
     ]
    }
   ],
   "source": [
    "original_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Original accuracy with all features: {original_accuracy:.6f}\")\n",
    "\n",
    "feature_names = numerical_cols.copy()\n",
    "ohe = preprocessor.named_transformers_['cat']\n",
    "ohe_feature_names = ohe.get_feature_names_out(categorical_cols)\n",
    "feature_names.extend(ohe_feature_names)\n",
    "\n",
    "print(f\"Total number of features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7decbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy with all features: 0.684932\n",
      "Total number of features: 27\n"
     ]
    }
   ],
   "source": [
    "original_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Original accuracy with all features: {original_accuracy:.6f}\")\n",
    "\n",
    "feature_names = numerical_cols.copy()\n",
    "ohe = preprocessor.named_transformers_['cat']\n",
    "ohe_feature_names = ohe.get_feature_names_out(categorical_cols)\n",
    "feature_names.extend(ohe_feature_names)\n",
    "\n",
    "print(f\"Total number of features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33cc5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_without_feature(feature_to_exclude, original_feature_names):\n",
    "    is_categorical = any(feature_to_exclude in cat_col for cat_col in categorical_cols)\n",
    "    \n",
    "    if is_categorical:\n",
    "        cols_to_exclude = [f for f in original_feature_names if feature_to_exclude in f]\n",
    "        print(f\"Excluding categorical feature '{feature_to_exclude}': {cols_to_exclude}\")\n",
    "    else:\n",
    "        cols_to_exclude = [feature_to_exclude]\n",
    "        print(f\"Excluding numerical feature '{feature_to_exclude}'\")\n",
    "    \n",
    "    indices_to_keep = [i for i, f in enumerate(original_feature_names) if f not in cols_to_exclude]\n",
    "    \n",
    "    X_train_subset = X_train_processed[:, indices_to_keep]\n",
    "    X_val_subset = X_val_processed[:, indices_to_keep]\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_subset, y_train)\n",
    "    \n",
    "    y_val_pred_subset = model.predict(X_val_subset)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred_subset)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "386da653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing without feature: industry ===\n",
      "Excluding categorical feature 'industry': ['industry_education', 'industry_finance', 'industry_healthcare', 'industry_manufacturing', 'industry_other', 'industry_retail', 'industry_technology']\n",
      "Accuracy without industry: 0.684932\n",
      "Difference from original: 0.000000\n",
      "\n",
      "=== Testing without feature: employment_status ===\n",
      "Excluding categorical feature 'employment_status': ['employment_status_employed', 'employment_status_self_employed', 'employment_status_student', 'employment_status_unemployed']\n",
      "Accuracy without employment_status: 0.681507\n",
      "Difference from original: 0.003425\n",
      "\n",
      "=== Testing without feature: lead_score ===\n",
      "Excluding numerical feature 'lead_score'\n",
      "Accuracy without lead_score: 0.678082\n",
      "Difference from original: 0.006849\n"
     ]
    }
   ],
   "source": [
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "\n",
    "accuracy_differences = {}\n",
    "\n",
    "for feature in features_to_test:\n",
    "    print(f\"\\n=== Testing without feature: {feature} ===\")\n",
    "    \n",
    "    accuracy_without_feature = train_without_feature(feature, feature_names)\n",
    "    \n",
    "    difference = original_accuracy - accuracy_without_feature\n",
    "    \n",
    "    accuracy_differences[feature] = {\n",
    "        'accuracy_without': accuracy_without_feature,\n",
    "        'difference': difference\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy without {feature}: {accuracy_without_feature:.6f}\")\n",
    "    print(f\"Difference from original: {difference:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5f5d79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE ELIMINATION RESULTS\n",
      "============================================================\n",
      "Original accuracy: 0.684932\n",
      "\n",
      "industry             | Accuracy without: 0.684932 | Difference: +0.000000\n",
      "employment_status    | Accuracy without: 0.681507 | Difference: +0.003425\n",
      "lead_score           | Accuracy without: 0.678082 | Difference: +0.006849\n",
      "\n",
      "The feature with the smallest difference is: 'industry'\n",
      "Difference: 0.000000 (absolute: 0.000000)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ELIMINATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original accuracy: {original_accuracy:.6f}\\n\")\n",
    "\n",
    "for feature in features_to_test:\n",
    "    diff = accuracy_differences[feature]['difference']\n",
    "    acc_without = accuracy_differences[feature]['accuracy_without']\n",
    "    print(f\"{feature:20} | Accuracy without: {acc_without:.6f} | Difference: {diff:+.6f}\")\n",
    "\n",
    "feature_with_smallest_diff = min(accuracy_differences.keys(), \n",
    "                                key=lambda x: abs(accuracy_differences[x]['difference']))\n",
    "\n",
    "smallest_diff = accuracy_differences[feature_with_smallest_diff]['difference']\n",
    "smallest_abs_diff = abs(smallest_diff)\n",
    "\n",
    "print(f\"\\nThe feature with the smallest difference is: '{feature_with_smallest_diff}'\")\n",
    "print(f\"Difference: {smallest_diff:.6f} (absolute: {smallest_abs_diff:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8050bdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training regularized logistic regression models with different C values:\n",
      "============================================================\n",
      "C =  0.01 | Validation Accuracy: 0.688356 | Rounded: 0.688\n",
      "C =   0.1 | Validation Accuracy: 0.681507 | Rounded: 0.682\n",
      "C =     1 | Validation Accuracy: 0.684932 | Rounded: 0.685\n",
      "C =    10 | Validation Accuracy: 0.684932 | Rounded: 0.685\n",
      "C =   100 | Validation Accuracy: 0.684932 | Rounded: 0.685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Training regularized logistic regression models with different C values:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val_processed)\n",
    "    \n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_rounded = round(val_accuracy, 3)\n",
    "    \n",
    "    results[C] = {\n",
    "        'accuracy': val_accuracy,\n",
    "        'accuracy_rounded': val_accuracy_rounded\n",
    "    }\n",
    "    \n",
    "    print(f\"C = {C:5} | Validation Accuracy: {val_accuracy:.6f} | Rounded: {val_accuracy_rounded:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22bc42ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best C value: 0.01\n",
      "Best validation accuracy: 0.688356\n",
      "Best validation accuracy (rounded to 3 decimals): 0.688\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = -1\n",
    "best_C = None\n",
    "\n",
    "for C, result in results.items():\n",
    "    if result['accuracy'] > best_accuracy:\n",
    "        best_accuracy = result['accuracy']\n",
    "        best_C = C\n",
    "\n",
    "print(f\"\\nBest C value: {best_C}\")\n",
    "print(f\"Best validation accuracy: {best_accuracy:.6f}\")\n",
    "print(f\"Best validation accuracy (rounded to 3 decimals): {round(best_accuracy, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e111e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C values grouped by rounded accuracy:\n",
      "Accuracy 0.688: C values [0.01]\n",
      "Accuracy 0.685: C values [1, 10, 100]\n",
      "  -> Multiple C values achieve this accuracy. Smallest C: 1\n",
      "Accuracy 0.682: C values [0.1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_groups = {}\n",
    "\n",
    "for C, result in results.items():\n",
    "    rounded_acc = result['accuracy_rounded']\n",
    "    if rounded_acc not in accuracy_groups:\n",
    "        accuracy_groups[rounded_acc] = []\n",
    "    accuracy_groups[rounded_acc].append(C)\n",
    "\n",
    "print(\"\\nC values grouped by rounded accuracy:\")\n",
    "for acc, C_list in sorted(accuracy_groups.items(), reverse=True):\n",
    "    C_list_sorted = sorted(C_list)\n",
    "    print(f\"Accuracy {acc}: C values {C_list_sorted}\")\n",
    "    \n",
    "    if len(C_list) > 1:\n",
    "        print(f\"  -> Multiple C values achieve this accuracy. Smallest C: {C_list_sorted[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08ac9c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL RESULT:\n",
      "Best rounded accuracy: 0.688\n",
      "C values achieving this accuracy: [0.01]\n",
      "Selected C (smallest among best): 0.01\n"
     ]
    }
   ],
   "source": [
    "best_rounded_accuracy = max(accuracy_groups.keys())\n",
    "best_C_candidates = accuracy_groups[best_rounded_accuracy]\n",
    "best_C_final = min(best_C_candidates)  \n",
    "\n",
    "print(f\"\\nFINAL RESULT:\")\n",
    "print(f\"Best rounded accuracy: {best_rounded_accuracy}\")\n",
    "print(f\"C values achieving this accuracy: {best_C_candidates}\")\n",
    "print(f\"Selected C (smallest among best): {best_C_final}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
