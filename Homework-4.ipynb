{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cee8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "url =\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113f9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 876 (59.9%)\n",
      "Val: 293 (20.0%)\n",
      "Test: 293 (20.0%)\n",
      "lead_score: AUC = 0.6145\n",
      "number_of_courses_viewed: AUC = 0.7636\n",
      "interaction_count: AUC = 0.7383\n",
      "annual_income: AUC = 0.5520\n",
      "\n",
      "The numerical variable with the highest AUC is: number_of_courses_viewed (AUC = 0.7636)\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].fillna('NA')\n",
    "    \n",
    "for col in numerical_columns:\n",
    "    df[col] = df[col].fillna(0.0)\n",
    "    df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "print(f\"Train: {len(df_train)} ({len(df_train)/len(df):.1%})\")\n",
    "print(f\"Val: {len(df_val)} ({len(df_val)/len(df):.1%})\")\n",
    "print(f\"Test: {len(df_test)} ({len(df_test)/len(df):.1%})\")\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "y_train = df_train['converted']\n",
    "numerical_vars = ['lead_score', 'number_of_courses_viewed', 'interaction_count', 'annual_income']\n",
    "\n",
    "auc_scores = {}\n",
    "\n",
    "for var in numerical_vars:\n",
    "    if var in df_train.columns:\n",
    "        auc = roc_auc_score(y_train, df_train[var])\n",
    "        \n",
    "        if auc < 0.5:\n",
    "            auc = roc_auc_score(y_train, -df_train[var])\n",
    "            print(f\"{var}: Original AUC < 0.5, using inverted variable\")\n",
    "        \n",
    "        auc_scores[var] = auc\n",
    "        print(f\"{var}: AUC = {auc:.4f}\")\n",
    "\n",
    "best_variable = max(auc_scores, key=auc_scores.get)\n",
    "highest_auc = auc_scores[best_variable]\n",
    "\n",
    "print(f\"\\nThe numerical variable with the highest AUC is: {best_variable} (AUC = {highest_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69ffee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 876\n",
      "Val: 293\n",
      "Test: 293\n",
      "\n",
      "Validation AUC: 0.817\n",
      "Rounded AUC: 0.817\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].fillna('NA')\n",
    "    \n",
    "for col in numerical_columns:\n",
    "    df[col] = df[col].fillna(0.0)\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "print(f\"Train: {len(df_train)}\")\n",
    "print(f\"Val: {len(df_val)}\")\n",
    "print(f\"Test: {len(df_test)}\")\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train['converted'].values\n",
    "y_val = df_val['converted'].values\n",
    "y_test = df_test['converted'].values\n",
    "\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']\n",
    "\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "val_dict = df_val.to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "print(f\"\\nValidation AUC: {auc_val:.3f}\")\n",
    "\n",
    "auc_rounded = round(auc_val, 3)\n",
    "print(f\"Rounded AUC: {auc_rounded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1238e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision and recall intersect at threshold: 0.980\n",
      "At this threshold - Precision: 0.000, Recall: 0.000\n",
      "\n",
      "Closest option to 0.980 is: 0.745\n",
      "\n",
      "Near the intersection point:\n",
      "Threshold: 0.960, Precision: 1.000, Recall: 0.018, Diff: 0.982\n",
      "Threshold: 0.970, Precision: 1.000, Recall: 0.006, Diff: 0.994\n",
      "Threshold: 0.980, Precision: 0.000, Recall: 0.000, Diff: 0.000\n",
      "Threshold: 0.990, Precision: 0.000, Recall: 0.000, Diff: 0.000\n",
      "Threshold: 1.000, Precision: 0.000, Recall: 0.000, Diff: 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "y_pred_val = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_binary = (y_pred_val >= t).astype(int)\n",
    "    precision = precision_score(y_val, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred_binary, zero_division=0)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'threshold': thresholds,\n",
    "    'precision': precisions,\n",
    "    'recall': recalls\n",
    "})\n",
    "\n",
    "metrics_df['diff'] = np.abs(metrics_df['precision'] - metrics_df['recall'])\n",
    "intersection_point = metrics_df.loc[metrics_df['diff'].idxmin()]\n",
    "\n",
    "print(f\"Precision and recall intersect at threshold: {intersection_point['threshold']:.3f}\")\n",
    "print(f\"At this threshold - Precision: {intersection_point['precision']:.3f}, Recall: {intersection_point['recall']:.3f}\")\n",
    "\n",
    "options = [0.145, 0.345, 0.545, 0.745]\n",
    "closest_option = min(options, key=lambda x: abs(x - intersection_point['threshold']))\n",
    "print(f\"\\nClosest option to {intersection_point['threshold']:.3f} is: {closest_option}\")\n",
    "\n",
    "print(\"\\nNear the intersection point:\")\n",
    "start_idx = max(0, metrics_df['diff'].idxmin() - 2)\n",
    "end_idx = min(len(metrics_df), metrics_df['diff'].idxmin() + 3)\n",
    "for idx in range(start_idx, end_idx):\n",
    "    row = metrics_df.iloc[idx]\n",
    "    print(f\"Threshold: {row['threshold']:.3f}, Precision: {row['precision']:.3f}, Recall: {row['recall']:.3f}, Diff: {row['diff']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b905c378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum F1 score: 0.8125\n",
      "Threshold at maximum F1: 0.570\n",
      "At this threshold - Precision: 0.732, Recall: 0.912\n",
      "\n",
      "Closest option to 0.570 is: 0.54\n",
      "\n",
      "Top F1 scores:\n",
      "Threshold: 0.570, F1: 0.8125, Precision: 0.732, Recall: 0.912\n",
      "Threshold: 0.550, F1: 0.8112, Precision: 0.719, Recall: 0.930\n",
      "Threshold: 0.560, F1: 0.8093, Precision: 0.724, Recall: 0.918\n",
      "Threshold: 0.590, F1: 0.8085, Precision: 0.741, Recall: 0.889\n",
      "Threshold: 0.580, F1: 0.8084, Precision: 0.733, Recall: 0.901\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_val = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_binary = (y_pred_val >= t).astype(int)\n",
    "    precision = precision_score(y_val, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred_binary, zero_division=0)\n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    \n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'threshold': thresholds,\n",
    "    'precision': precisions,\n",
    "    'recall': recalls,\n",
    "    'f1': f1_scores\n",
    "})\n",
    "\n",
    "max_f1_row = metrics_df.loc[metrics_df['f1'].idxmax()]\n",
    "\n",
    "print(f\"Maximum F1 score: {max_f1_row['f1']:.4f}\")\n",
    "print(f\"Threshold at maximum F1: {max_f1_row['threshold']:.3f}\")\n",
    "print(f\"At this threshold - Precision: {max_f1_row['precision']:.3f}, Recall: {max_f1_row['recall']:.3f}\")\n",
    "\n",
    "options = [0.14, 0.34, 0.54, 0.74]\n",
    "closest_option = min(options, key=lambda x: abs(x - max_f1_row['threshold']))\n",
    "print(f\"\\nClosest option to {max_f1_row['threshold']:.3f} is: {closest_option}\")\n",
    "\n",
    "print(\"\\nTop F1 scores:\")\n",
    "top_f1 = metrics_df.nlargest(5, 'f1')[['threshold', 'f1', 'precision', 'recall']]\n",
    "for idx, row in top_f1.iterrows():\n",
    "    print(f\"Threshold: {row['threshold']:.3f}, F1: {row['f1']:.4f}, Precision: {row['precision']:.3f}, Recall: {row['recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f9a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold AUC: 0.8180\n",
      "Fold AUC: 0.8035\n",
      "Fold AUC: 0.8425\n",
      "Fold AUC: 0.8024\n",
      "Fold AUC: 0.8448\n",
      "\n",
      "Cross-validation results:\n",
      "Mean AUC: 0.8222\n",
      "Standard deviation: 0.0183\n",
      "\n",
      "Closest option to std 0.0183 is: 0.006\n",
      "\n",
      "All AUC scores: ['0.8180', '0.8035', '0.8425', '0.8024', '0.8448']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df_full_train = pd.concat([df_train, df_val], ignore_index=True)\n",
    "y_full_train = pd.concat([pd.Series(y_train), pd.Series(y_val)], ignore_index=True)\n",
    "\n",
    "# Prepare the features as dictionaries\n",
    "df_full_train_features = df_full_train.copy()\n",
    "full_train_dict = df_full_train_features.to_dict(orient='records')\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Store AUC scores for each fold\n",
    "auc_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_idx, val_idx in kf.split(full_train_dict):\n",
    "    # Split the data\n",
    "    X_train_fold = [full_train_dict[i] for i in train_idx]\n",
    "    X_val_fold = [full_train_dict[i] for i in val_idx]\n",
    "    \n",
    "    y_train_fold = y_full_train.iloc[train_idx]\n",
    "    y_val_fold = y_full_train.iloc[val_idx]\n",
    "    \n",
    "    # Apply DictVectorizer\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train_encoded = dv.fit_transform(X_train_fold)\n",
    "    X_val_encoded = dv.transform(X_val_fold)\n",
    "    \n",
    "    # Train the model\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model.fit(X_train_encoded, y_train_fold)\n",
    "    \n",
    "    y_pred_val = model.predict_proba(X_val_encoded)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(y_val_fold, y_pred_val)\n",
    "    auc_scores.append(auc)\n",
    "    \n",
    "    print(f\"Fold AUC: {auc:.4f}\")\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "\n",
    "print(f\"\\nCross-validation results:\")\n",
    "print(f\"Mean AUC: {mean_auc:.4f}\")\n",
    "print(f\"Standard deviation: {std_auc:.4f}\")\n",
    "\n",
    "options = [0.0001, 0.006, 0.06, 0.36]\n",
    "closest_option = min(options, key=lambda x: abs(x - std_auc))\n",
    "print(f\"\\nClosest option to std {std_auc:.4f} is: {closest_option}\")\n",
    "\n",
    "print(f\"\\nAll AUC scores: {[f'{score:.4f}' for score in auc_scores]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2547636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing C = 1e-06\n",
      "  Fold 1 AUC: 0.5804\n",
      "  Fold 2 AUC: 0.5751\n",
      "  Fold 3 AUC: 0.5199\n",
      "  Fold 4 AUC: 0.6251\n",
      "  Fold 5 AUC: 0.5070\n",
      "  Mean AUC: 0.5615 ± 0.0431\n",
      "\n",
      "Testing C = 0.001\n",
      "  Fold 1 AUC: 0.8591\n",
      "  Fold 2 AUC: 0.8448\n",
      "  Fold 3 AUC: 0.8877\n",
      "  Fold 4 AUC: 0.8614\n",
      "  Fold 5 AUC: 0.8798\n",
      "  Mean AUC: 0.8666 ± 0.0154\n",
      "\n",
      "Testing C = 1\n",
      "  Fold 1 AUC: 0.8180\n",
      "  Fold 2 AUC: 0.8035\n",
      "  Fold 3 AUC: 0.8425\n",
      "  Fold 4 AUC: 0.8024\n",
      "  Fold 5 AUC: 0.8448\n",
      "  Mean AUC: 0.8222 ± 0.0183\n",
      "\n",
      "==================================================\n",
      "FINAL RESULTS:\n",
      "==================================================\n",
      "C =    0.001 | Mean AUC: 0.867 | Std: 0.015\n",
      "C =        1 | Mean AUC: 0.822 | Std: 0.018\n",
      "C =    1e-06 | Mean AUC: 0.561 | Std: 0.043\n",
      "\n",
      "Best C: 0.001\n",
      "Best mean AUC: 0.867\n",
      "Best std: 0.015\n",
      "\n",
      "Selection process:\n",
      "1. Highest mean AUC: 0.867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "df_full_train = pd.concat([df_train, df_val], ignore_index=True)\n",
    "y_full_train = pd.concat([pd.Series(y_train), pd.Series(y_val)], ignore_index=True)\n",
    "\n",
    "df_full_train_features = df_full_train.copy()\n",
    "full_train_dict = df_full_train_features.to_dict(orient='records')\n",
    "\n",
    "C_values = [0.000001, 0.001, 1]\n",
    "\n",
    "results = []\n",
    "\n",
    "for C in C_values:\n",
    "    print(f\"\\nTesting C = {C}\")\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    \n",
    "    auc_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(full_train_dict)):\n",
    "        X_train_fold = [full_train_dict[i] for i in train_idx]\n",
    "        X_val_fold = [full_train_dict[i] for i in val_idx]\n",
    "        \n",
    "        y_train_fold = y_full_train.iloc[train_idx]\n",
    "        y_val_fold = y_full_train.iloc[val_idx]\n",
    "        \n",
    "        dv = DictVectorizer(sparse=False)\n",
    "        X_train_encoded = dv.fit_transform(X_train_fold)\n",
    "        X_val_encoded = dv.transform(X_val_fold)\n",
    "        \n",
    "        model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "        model.fit(X_train_encoded, y_train_fold)\n",
    "        \n",
    "        y_pred_val = model.predict_proba(X_val_encoded)[:, 1]\n",
    "        \n",
    "        auc = roc_auc_score(y_val_fold, y_pred_val)\n",
    "        auc_scores.append(auc)\n",
    "        \n",
    "        print(f\"  Fold {fold+1} AUC: {auc:.4f}\")\n",
    "    \n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    std_auc = np.std(auc_scores)\n",
    "    \n",
    "    results.append({\n",
    "        'C': C,\n",
    "        'mean_auc': mean_auc,\n",
    "        'std_auc': std_auc,\n",
    "        'auc_scores': auc_scores.copy()\n",
    "    })\n",
    "    \n",
    "    print(f\"  Mean AUC: {mean_auc:.4f} ± {std_auc:.4f}\")\n",
    "\n",
    "results_sorted = sorted(results, key=lambda x: (-x['mean_auc'], x['std_auc'], x['C']))\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(f\"{'='*50}\")\n",
    "for res in results_sorted:\n",
    "    print(f\"C = {res['C']:8} | Mean AUC: {res['mean_auc']:.3f} | Std: {res['std_auc']:.3f}\")\n",
    "\n",
    "best_C = results_sorted[0]['C']\n",
    "best_mean = results_sorted[0]['mean_auc']\n",
    "best_std = results_sorted[0]['std_auc']\n",
    "\n",
    "print(f\"\\nBest C: {best_C}\")\n",
    "print(f\"Best mean AUC: {best_mean:.3f}\")\n",
    "print(f\"Best std: {best_std:.3f}\")\n",
    "\n",
    "print(f\"\\nSelection process:\")\n",
    "print(f\"1. Highest mean AUC: {results_sorted[0]['mean_auc']:.3f}\")\n",
    "if len(results_sorted) > 1 and results_sorted[0]['mean_auc'] == results_sorted[1]['mean_auc']:\n",
    "    print(f\"2. Tie in mean AUC, selecting lower std: {results_sorted[0]['std_auc']:.3f}\")\n",
    "    if results_sorted[0]['std_auc'] == results_sorted[1]['std_auc']:\n",
    "        print(f\"3. Tie in std, selecting smallest C: {results_sorted[0]['C']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
